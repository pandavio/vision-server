from flask import Flask, request, jsonify
from flask_cors import CORS
import base64
import openai
import os

import torch
from PIL import Image
from io import BytesIO

print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– OpenAI + YOLO è§†è§‰æœåŠ¡å™¨...")

# OpenAI åˆå§‹åŒ–
client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# YOLOv5 åŠ è½½ï¼ˆæœ¬åœ°æ¨¡å‹ï¼‰
print("ğŸ” æ­£åœ¨åŠ è½½ YOLOv5 æœ¬åœ°æ¨¡å‹...")
yolo_model = torch.hub.load(
    repo_or_dir='yolov5',
    model='custom',
    path='yolov5/models/yolov5s.pt',
    source='local'
)
yolo_model.eval()

# YOLO æ£€æµ‹å‡½æ•°
def run_yolo_detection(base64_img):
    try:
        image_data = base64.b64decode(base64_img)
        image = Image.open(BytesIO(image_data)).convert("RGB")
        results = yolo_model(image)
        labels = results.pandas().xyxy[0]['name'].tolist()
        print(f"ğŸŸ¢ YOLO è¯†åˆ«åˆ°: {labels}")
        return labels
    except Exception as e:
        print("âŒ YOLOè¯†åˆ«å¤±è´¥:", e)
        return []

# Flask åˆå§‹åŒ–
app = Flask(__name__)
CORS(app)
app.config['JSON_AS_ASCII'] = False

@app.route("/ping", methods=["GET"])
def ping():
    return "pong", 200

@app.route("/analyze", methods=["POST"])
def analyze():
    try:
        data = request.get_json(force=True)
        if not data or 'image' not in data or 'question' not in data:
            return jsonify({"error": "Missing image or question"}), 400

        base64_image = data['image']
        question = data['question']
        system_prompt = data.get('system_prompt', '')
        print("ğŸ“¥ æ”¶åˆ°è¯·æ±‚ï¼Œé—®é¢˜:", question)

        # YOLO æ£€æµ‹æ ‡ç­¾
        labels = run_yolo_detection(base64_image)
        labels_text = ", ".join(labels) if labels else "æœªæ£€æµ‹åˆ°ç‰©ä½“"

        # æ£€æŸ¥è¯­è¨€
        is_chinese = any('\u4e00' <= c <= '\u9fff' for c in question)

        # æ‹¼æ¥ system prompt
        if is_chinese:
            extra_zh = ""
            if "æˆ·å¤–" in system_prompt:
                extra_zh = "ç‰¹åˆ«å…³æ³¨çº¢ç»¿ç¯ã€æ–‘é©¬çº¿ã€ç›²é“ã€éšœç¢ç‰©ã€å›´å¢™ã€è½¬è§’ã€æ²Ÿæ¸ ç­‰ã€‚"
            elif "å®¤å†…" in system_prompt:
                extra_zh = "ç‰¹åˆ«å…³æ³¨å•æ‰€ã€å…¥å£ã€å‡ºå£ã€å¤§é—¨ç­‰è®¾æ–½ã€‚"

            system_prompt += f"\nå½“å‰è¯†åˆ«åˆ°çš„ç‰©ä½“æœ‰ï¼š{labels_text}ã€‚\nè¯·æ ¹æ®å›¾åƒå’Œç‰©ä½“ï¼Œä¸ºè§†éšœäººå£«æä¾›ç®€æ´æ¸…æ™°çš„ä¸­æ–‡æè¿°ã€‚{extra_zh}"

        else:
            extra_en = ""
            if "outdoor" in system_prompt:
                extra_en = "Pay special attention to traffic lights, crosswalks, tactile paving, obstacles, fences, corners, or ditches."
            elif "indoor" in system_prompt:
                extra_en = "Pay special attention to toilets, entrances, exits, or main doors."

            system_prompt += f"\nObjects detected: {labels_text}.\nPlease describe the environment clearly for a blind user. {extra_en}"

        print(f"ğŸŒ GPT-4o æç¤ºè¯­:\n{system_prompt}")

        # è°ƒç”¨ GPT
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": [
                    {"type": "text", "text": question},
                    {"type": "image_url", "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }}
                ]}
            ],
            max_tokens=1000
        )

        final_answer = response.choices[0].message.content.strip()
        print(f"ğŸ¤– GPT å›ç­”: {final_answer}")

        return jsonify({
            "question": question,
            "mode": "gpt4o",
            "answer": final_answer,
            "labels": labels
        })

    except Exception as e:
        print("âŒ å‘ç”Ÿé”™è¯¯:", str(e))
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    print(f"ğŸš€ æ­£åœ¨ç›‘å¬ç«¯å£ {port}")
    app.run(host="0.0.0.0", port=port)
